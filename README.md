# DATA-PIPELINE-DEVELOPMENT

This project demonstrates a simple ETL (Extract, Transform, Load) pipeline built with Python using basic libraries such as pandas and scikit-learn. The pipeline processes employee data by extracting from a CSV, performing basic cleaning and transformations, and saving the cleaned data for downstream usage.

ğŸ“ Project Structure
etl-pipeline/ â”‚ â”œâ”€â”€ employee_data.csv # Raw input data â”œâ”€â”€ processed_employee_data.csv # Output after ETL â”œâ”€â”€ extract.py # Script to generate or extract employee data â”œâ”€â”€ ETL_TRANSFORM.py # ETL script (transform and load) â””â”€â”€ README.md # Project documentation

âœ… Features
Extracts data from a CSV file.
Handles missing values using forward fill.
Encodes categorical columns using label encoding.
Scales numerical values like salary.
Outputs the cleaned data to a new CSV file.
ğŸ› ï¸ Requirements
Python 3.x
pandas
scikit-learn
You can install dependencies with:

pip install pandas scikit-learn
python extract.py
python ETL_TRANSFORM.py
processed_employee_data.csv
